{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# EIA Crude Oil Data Analysis using Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This research is mainly to utilize EIA api to import data, and apply machine learning techniques to predict Crude Oil Futures price movement, using all factors associated with EIA\n",
    "\n",
    "Example of API data was given in the link below (Put your API key in the YOUR_API_KEY_HERE area in order to obtain data): <br>\n",
    "http://api.eia.gov/series/?api_key=YOUR_API_KEY_HERE&series_id=PET.WCRFPUS2.W\n",
    "\n",
    "All data are given in this link (hit the key button will show API link): <br>\n",
    "https://www.eia.gov/dnav/pet/pet_sum_sndw_dcus_nus_w.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import statsmodels.api as sm # Apply Simple Multi-Linear Regression for analysis\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import data using requests packages, we will first try on 3 key data below:<br>\n",
    "Series ID = PET.WCRFPUS2.W #US Field Production of Crude Oil Weekly <br>\n",
    "Series ID = PET.WCRRIUS2.W #US Refiner Net Input of Crude Oil<br>\n",
    "Series ID = PET.WTTIMUS2.W #US Imports of Crude Oil and Petroleum Products, Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"af034aec5e5242b2bc1ccaef0c93887c\"\n",
    "series_id = ['PET.WCRFPUS2.W', 'PET.WCRRIUS2.W', 'PET.WTTIMUS2.W']\n",
    "\n",
    "df = pd.DataFrame() # Declare dataframe\n",
    "\n",
    "for i in series_id:\n",
    "    data = requests.get('http://api.eia.gov/series/?api_key=' + api_key + '&series_id=' + i).json()\n",
    "    data = pd.DataFrame(data['series'])\n",
    "    \n",
    "    headers = [\"time\", i]\n",
    "    tmp = data[['data']]\n",
    "    tmp = tmp['data'][0]\n",
    "    tmpdf = pd.DataFrame(tmp, columns = headers)\n",
    "    df = pd.concat([df, tmpdf], axis = 1)\n",
    "\n",
    "\n",
    "df = df.iloc[:, ~df.columns.duplicated()]\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.sort_values(by = ['time']) # Sort the dataframe ascending by time\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is how the dataframe looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>PET.WCRFPUS2.W</th>\n",
       "      <th>PET.WCRRIUS2.W</th>\n",
       "      <th>PET.WTTIMUS2.W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>1991-02-08</td>\n",
       "      <td>7463.0</td>\n",
       "      <td>12973</td>\n",
       "      <td>6877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>1991-02-15</td>\n",
       "      <td>7427.0</td>\n",
       "      <td>12931</td>\n",
       "      <td>6573.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>1991-02-22</td>\n",
       "      <td>7415.0</td>\n",
       "      <td>13107</td>\n",
       "      <td>6221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>1991-03-01</td>\n",
       "      <td>7404.0</td>\n",
       "      <td>13164</td>\n",
       "      <td>6188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>1991-03-08</td>\n",
       "      <td>7394.0</td>\n",
       "      <td>13082</td>\n",
       "      <td>7127.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           time  PET.WCRFPUS2.W  PET.WCRRIUS2.W  PET.WTTIMUS2.W\n",
       "1424 1991-02-08          7463.0           12973          6877.0\n",
       "1423 1991-02-15          7427.0           12931          6573.0\n",
       "1422 1991-02-22          7415.0           13107          6221.0\n",
       "1421 1991-03-01          7404.0           13164          6188.0\n",
       "1420 1991-03-08          7394.0           13082          7127.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining Historical price data from Quandl api:\n",
    "https://www.quandl.com/api/v3/datasets/CHRIS/CME_CL1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Change</th>\n",
       "      <th>Settle</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Previous Day Open Interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8837</th>\n",
       "      <td>1983-03-30</td>\n",
       "      <td>29.01</td>\n",
       "      <td>29.56</td>\n",
       "      <td>29.01</td>\n",
       "      <td>29.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.40</td>\n",
       "      <td>949.0</td>\n",
       "      <td>470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8836</th>\n",
       "      <td>1983-03-31</td>\n",
       "      <td>29.40</td>\n",
       "      <td>29.60</td>\n",
       "      <td>29.25</td>\n",
       "      <td>29.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.29</td>\n",
       "      <td>521.0</td>\n",
       "      <td>523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8835</th>\n",
       "      <td>1983-04-04</td>\n",
       "      <td>29.30</td>\n",
       "      <td>29.70</td>\n",
       "      <td>29.29</td>\n",
       "      <td>29.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.44</td>\n",
       "      <td>156.0</td>\n",
       "      <td>583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8834</th>\n",
       "      <td>1983-04-05</td>\n",
       "      <td>29.50</td>\n",
       "      <td>29.80</td>\n",
       "      <td>29.50</td>\n",
       "      <td>29.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.71</td>\n",
       "      <td>175.0</td>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8833</th>\n",
       "      <td>1983-04-06</td>\n",
       "      <td>29.90</td>\n",
       "      <td>29.92</td>\n",
       "      <td>29.65</td>\n",
       "      <td>29.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.90</td>\n",
       "      <td>392.0</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           time   Open   High    Low   Last  Change  Settle  Volume  \\\n",
       "8837 1983-03-30  29.01  29.56  29.01  29.40     NaN   29.40   949.0   \n",
       "8836 1983-03-31  29.40  29.60  29.25  29.29     NaN   29.29   521.0   \n",
       "8835 1983-04-04  29.30  29.70  29.29  29.44     NaN   29.44   156.0   \n",
       "8834 1983-04-05  29.50  29.80  29.50  29.71     NaN   29.71   175.0   \n",
       "8833 1983-04-06  29.90  29.92  29.65  29.90     NaN   29.90   392.0   \n",
       "\n",
       "      Previous Day Open Interest  \n",
       "8837                       470.0  \n",
       "8836                       523.0  \n",
       "8835                       583.0  \n",
       "8834                       623.0  \n",
       "8833                       640.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = requests.get('https://www.quandl.com/api/v3/datasets/CHRIS/CME_CL1').json()\n",
    "\n",
    "keys = list(data['dataset'].keys())\n",
    "data = data['dataset']\n",
    "price = data['data']\n",
    "headers = data['column_names']\n",
    "price_df = pd.DataFrame(price, columns = headers)\n",
    "price_df = price_df.rename(columns = {'Date':'time'}) # Change Date column name into time to be consistent\n",
    "price_df['time'] = pd.to_datetime(price_df['time'])\n",
    "price_df = price_df.sort_values(by = ['time']) # Sort the dataframe ascending by time\n",
    "price_df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Factors Data and Historical pricing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(price_df, left_on = 'time', right_on = 'time', how = 'left')\n",
    "df = df.drop(columns = ['Change', 'Open', 'High', 'Low', 'Settle'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>PET.WCRFPUS2.W</th>\n",
       "      <th>PET.WCRRIUS2.W</th>\n",
       "      <th>PET.WTTIMUS2.W</th>\n",
       "      <th>Last</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Previous Day Open Interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-02-15</td>\n",
       "      <td>-0.004824</td>\n",
       "      <td>-0.003237</td>\n",
       "      <td>-0.044205</td>\n",
       "      <td>-0.142241</td>\n",
       "      <td>0.195222</td>\n",
       "      <td>-0.381740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1991-02-22</td>\n",
       "      <td>-0.001616</td>\n",
       "      <td>0.013611</td>\n",
       "      <td>-0.053552</td>\n",
       "      <td>0.082077</td>\n",
       "      <td>0.181597</td>\n",
       "      <td>0.572817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1991-03-01</td>\n",
       "      <td>-0.001483</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>-0.005305</td>\n",
       "      <td>-0.003612</td>\n",
       "      <td>-0.521073</td>\n",
       "      <td>-0.107887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1991-03-08</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>-0.006229</td>\n",
       "      <td>0.151745</td>\n",
       "      <td>0.036251</td>\n",
       "      <td>0.256231</td>\n",
       "      <td>0.014883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1991-03-15</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.152378</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>-0.296973</td>\n",
       "      <td>-0.229741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  PET.WCRFPUS2.W  PET.WCRRIUS2.W  PET.WTTIMUS2.W      Last  \\\n",
       "1 1991-02-15       -0.004824       -0.003237       -0.044205 -0.142241   \n",
       "2 1991-02-22       -0.001616        0.013611       -0.053552  0.082077   \n",
       "3 1991-03-01       -0.001483        0.004349       -0.005305 -0.003612   \n",
       "4 1991-03-08       -0.001351       -0.006229        0.151745  0.036251   \n",
       "5 1991-03-15        0.002434       -0.020257       -0.152378  0.004498   \n",
       "\n",
       "     Volume  Previous Day Open Interest  \n",
       "1  0.195222                   -0.381740  \n",
       "2  0.181597                    0.572817  \n",
       "3 -0.521073                   -0.107887  \n",
       "4  0.256231                    0.014883  \n",
       "5 -0.296973                   -0.229741  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Changes in term of returns\n",
    "df.set_index('time')\n",
    "df['Last'] = df['Last'].shift(-1)\n",
    "df.iloc[:, 1:len(df.columns)] = (df.iloc[:, 1:len(df.columns)] - df.iloc[:, 1:len(df.columns)].shift(1)) / df.iloc[:, 1:len(df.columns)].shift(1)\n",
    "df = df.dropna()\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Multi-Linear-Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'PET.WCRFPUS2.W', 'PET.WCRRIUS2.W', 'PET.WTTIMUS2.W', 'Last',\n",
       "       'Volume', 'Previous Day Open Interest'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Last</td>       <th>  R-squared:         </th> <td>   0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.919</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 02 Jun 2018</td> <th>  Prob (F-statistic):</th>  <td> 0.125</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:43:59</td>     <th>  Log-Likelihood:    </th> <td>  2160.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1354</td>      <th>  AIC:               </th> <td>  -4313.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1350</td>      <th>  BIC:               </th> <td>  -4292.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>          <td>    0.0022</td> <td>    0.001</td> <td>    1.648</td> <td> 0.100</td> <td>   -0.000</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PET.WCRFPUS2.W</th> <td>    0.0693</td> <td>    0.068</td> <td>    1.016</td> <td> 0.310</td> <td>   -0.065</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PET.WCRRIUS2.W</th> <td>   -0.0925</td> <td>    0.069</td> <td>   -1.336</td> <td> 0.182</td> <td>   -0.228</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PET.WTTIMUS2.W</th> <td>   -0.0273</td> <td>    0.015</td> <td>   -1.802</td> <td> 0.072</td> <td>   -0.057</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>109.495</td> <th>  Durbin-Watson:     </th> <td>   2.145</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 574.138</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.120</td>  <th>  Prob(JB):          </th> <td>2.13e-125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.181</td>  <th>  Cond. No.          </th> <td>    58.7</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   Last   R-squared:                       0.004\n",
       "Model:                            OLS   Adj. R-squared:                  0.002\n",
       "Method:                 Least Squares   F-statistic:                     1.919\n",
       "Date:                Sat, 02 Jun 2018   Prob (F-statistic):              0.125\n",
       "Time:                        22:43:59   Log-Likelihood:                 2160.4\n",
       "No. Observations:                1354   AIC:                            -4313.\n",
       "Df Residuals:                    1350   BIC:                            -4292.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "const              0.0022      0.001      1.648      0.100      -0.000       0.005\n",
       "PET.WCRFPUS2.W     0.0693      0.068      1.016      0.310      -0.065       0.203\n",
       "PET.WCRRIUS2.W    -0.0925      0.069     -1.336      0.182      -0.228       0.043\n",
       "PET.WTTIMUS2.W    -0.0273      0.015     -1.802      0.072      -0.057       0.002\n",
       "==============================================================================\n",
       "Omnibus:                      109.495   Durbin-Watson:                   2.145\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              574.138\n",
       "Skew:                          -0.120   Prob(JB):                    2.13e-125\n",
       "Kurtosis:                       6.181   Cond. No.                         58.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Last']\n",
    "X = df[series_id]\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, most of the factors are insignificant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Neural Network Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(df['Last'], dtype = \"|S6\")\n",
    "X = df[series_id]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes = (30, 30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test)\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  b'-0.000'       0.00      0.00      0.00         3\n",
      "  b'-0.001'       0.00      0.00      0.00         3\n",
      "  b'-0.002'       0.00      0.00      0.00         3\n",
      "  b'-0.003'       0.00      0.00      0.00         6\n",
      "  b'-0.004'       0.00      0.00      0.00         4\n",
      "  b'-0.005'       0.00      0.00      0.00         4\n",
      "  b'-0.006'       0.00      0.00      0.00         3\n",
      "  b'-0.007'       0.00      0.00      0.00         1\n",
      "  b'-0.008'       0.00      0.00      0.00         6\n",
      "  b'-0.009'       0.00      0.00      0.00         3\n",
      "  b'-0.010'       0.00      0.00      0.00         2\n",
      "  b'-0.011'       0.00      0.00      0.00         1\n",
      "  b'-0.012'       0.00      0.00      0.00         1\n",
      "  b'-0.013'       0.00      0.00      0.00         2\n",
      "  b'-0.014'       0.50      0.50      0.50         2\n",
      "  b'-0.015'       0.00      0.00      0.00         5\n",
      "  b'-0.016'       0.00      0.00      0.00         2\n",
      "  b'-0.017'       0.00      0.00      0.00         3\n",
      "  b'-0.018'       0.00      0.00      0.00         2\n",
      "  b'-0.019'       0.00      0.00      0.00         6\n",
      "  b'-0.020'       0.00      0.00      0.00         3\n",
      "  b'-0.021'       0.00      0.00      0.00         2\n",
      "  b'-0.022'       0.00      0.00      0.00         5\n",
      "  b'-0.023'       0.00      0.00      0.00         2\n",
      "  b'-0.024'       0.00      0.00      0.00         1\n",
      "  b'-0.025'       0.00      0.00      0.00         2\n",
      "  b'-0.026'       0.00      0.00      0.00         0\n",
      "  b'-0.027'       0.00      0.00      0.00         2\n",
      "  b'-0.028'       0.00      0.00      0.00         1\n",
      "  b'-0.029'       0.00      0.00      0.00         1\n",
      "  b'-0.030'       0.00      0.00      0.00         4\n",
      "  b'-0.031'       0.00      0.00      0.00         1\n",
      "  b'-0.032'       0.00      0.00      0.00         2\n",
      "  b'-0.033'       0.00      0.00      0.00         2\n",
      "  b'-0.034'       0.00      0.00      0.00         5\n",
      "  b'-0.035'       0.00      0.00      0.00         4\n",
      "  b'-0.036'       0.00      0.00      0.00         2\n",
      "  b'-0.037'       0.00      0.00      0.00         1\n",
      "  b'-0.038'       0.00      0.00      0.00         3\n",
      "  b'-0.039'       0.00      0.00      0.00         3\n",
      "  b'-0.040'       0.00      0.00      0.00         2\n",
      "  b'-0.041'       0.00      0.00      0.00         5\n",
      "  b'-0.042'       0.00      0.00      0.00         3\n",
      "  b'-0.043'       0.00      0.00      0.00         1\n",
      "  b'-0.045'       0.00      0.00      0.00         2\n",
      "  b'-0.046'       0.00      0.00      0.00         3\n",
      "  b'-0.047'       0.00      0.00      0.00         2\n",
      "  b'-0.048'       0.00      0.00      0.00         3\n",
      "  b'-0.050'       0.00      0.00      0.00         1\n",
      "  b'-0.051'       0.00      0.00      0.00         1\n",
      "  b'-0.052'       0.00      0.00      0.00         0\n",
      "  b'-0.053'       0.00      0.00      0.00         3\n",
      "  b'-0.054'       0.00      0.00      0.00         1\n",
      "  b'-0.055'       0.00      0.00      0.00         1\n",
      "  b'-0.056'       0.00      0.00      0.00         0\n",
      "  b'-0.058'       0.00      0.00      0.00         1\n",
      "  b'-0.061'       0.00      0.00      0.00         2\n",
      "  b'-0.063'       0.00      0.00      0.00         1\n",
      "  b'-0.064'       0.00      0.00      0.00         1\n",
      "  b'-0.065'       0.00      0.00      0.00         4\n",
      "  b'-0.066'       0.00      0.00      0.00         1\n",
      "  b'-0.067'       0.00      0.00      0.00         2\n",
      "  b'-0.068'       0.00      0.00      0.00         1\n",
      "  b'-0.069'       0.00      0.00      0.00         2\n",
      "  b'-0.071'       0.00      0.00      0.00         1\n",
      "  b'-0.072'       0.00      0.00      0.00         0\n",
      "  b'-0.073'       0.00      0.00      0.00         0\n",
      "  b'-0.075'       0.00      0.00      0.00         1\n",
      "  b'-0.081'       0.00      0.00      0.00         0\n",
      "  b'-0.082'       0.00      0.00      0.00         1\n",
      "  b'-0.083'       0.00      0.00      0.00         1\n",
      "  b'-0.084'       0.00      0.00      0.00         1\n",
      "  b'-0.085'       0.00      0.00      0.00         2\n",
      "  b'-0.088'       0.00      0.00      0.00         1\n",
      "  b'-0.092'       0.00      0.00      0.00         1\n",
      "  b'-0.093'       0.00      0.00      0.00         2\n",
      "  b'-0.096'       0.00      0.00      0.00         4\n",
      "  b'-0.097'       0.00      0.00      0.00         1\n",
      "  b'-0.099'       0.00      0.00      0.00         2\n",
      "  b'-0.100'       0.00      0.00      0.00         1\n",
      "  b'-0.102'       0.00      0.00      0.00         0\n",
      "  b'-0.104'       0.00      0.00      0.00         1\n",
      "  b'-0.105'       0.00      0.00      0.00         1\n",
      "  b'-0.107'       0.00      0.00      0.00         0\n",
      "  b'-0.113'       0.00      0.00      0.00         0\n",
      "  b'-0.119'       0.00      0.00      0.00         0\n",
      "  b'-0.128'       0.00      0.00      0.00         1\n",
      "  b'-0.134'       0.00      0.00      0.00         1\n",
      "  b'-0.135'       0.00      0.00      0.00         0\n",
      "  b'-0.142'       0.00      0.00      0.00         1\n",
      "  b'-0.147'       0.00      0.00      0.00         0\n",
      "  b'-0.148'       0.00      0.00      0.00         0\n",
      "  b'-0.164'       0.00      0.00      0.00         0\n",
      "  b'-0.172'       0.00      0.00      0.00         0\n",
      "  b'-0.250'       0.00      0.00      0.00         1\n",
      "  b'0.0004'       0.00      0.00      0.00         1\n",
      "  b'0.0010'       0.00      0.00      0.00         0\n",
      "  b'0.0011'       0.00      0.00      0.00         1\n",
      "  b'0.0014'       0.00      0.00      0.00         1\n",
      "  b'0.0015'       0.00      0.00      0.00         1\n",
      "  b'0.0020'       0.00      0.00      0.00         0\n",
      "  b'0.0021'       0.00      0.00      0.00         1\n",
      "  b'0.0024'       0.00      0.00      0.00         0\n",
      "  b'0.0025'       0.00      0.00      0.00         0\n",
      "  b'0.0031'       0.00      0.00      0.00         1\n",
      "  b'0.0033'       0.00      0.00      0.00         1\n",
      "  b'0.0034'       0.00      0.00      0.00         2\n",
      "  b'0.0039'       0.00      0.00      0.00         0\n",
      "  b'0.0040'       0.00      0.00      0.00         0\n",
      "  b'0.0041'       0.00      0.00      0.00         0\n",
      "  b'0.0042'       0.00      0.00      0.00         1\n",
      "  b'0.0043'       0.00      0.00      0.00         1\n",
      "  b'0.0044'       0.00      0.00      0.00         2\n",
      "  b'0.0048'       0.00      0.00      0.00         1\n",
      "  b'0.0049'       0.00      0.00      0.00         1\n",
      "  b'0.0050'       0.00      0.00      0.00         1\n",
      "  b'0.0052'       0.00      0.00      0.00         0\n",
      "  b'0.0057'       0.00      0.00      0.00         1\n",
      "  b'0.0061'       0.00      0.00      0.00         0\n",
      "  b'0.0063'       0.00      0.00      0.00         0\n",
      "  b'0.0065'       0.00      0.00      0.00         1\n",
      "  b'0.0066'       0.00      0.00      0.00         2\n",
      "  b'0.0067'       0.00      0.00      0.00         1\n",
      "  b'0.0069'       0.00      0.00      0.00         1\n",
      "  b'0.0070'       0.00      0.00      0.00         1\n",
      "  b'0.0075'       0.00      0.00      0.00         0\n",
      "  b'0.0077'       0.00      0.00      0.00         0\n",
      "  b'0.0079'       0.00      0.00      0.00         1\n",
      "  b'0.0080'       0.00      0.00      0.00         2\n",
      "  b'0.0082'       0.00      0.00      0.00         0\n",
      "  b'0.0083'       0.00      0.00      0.00         1\n",
      "  b'0.0084'       0.00      0.00      0.00         0\n",
      "  b'0.0087'       0.00      0.00      0.00         1\n",
      "  b'0.0091'       0.00      0.00      0.00         2\n",
      "  b'0.0093'       0.00      0.00      0.00         2\n",
      "  b'0.0097'       0.00      0.00      0.00         1\n",
      "  b'0.0099'       0.00      0.00      0.00         2\n",
      "  b'0.0104'       0.00      0.00      0.00         0\n",
      "  b'0.0105'       0.00      0.00      0.00         0\n",
      "  b'0.0106'       0.00      0.00      0.00         1\n",
      "  b'0.0107'       0.00      0.00      0.00         0\n",
      "  b'0.0108'       0.00      0.00      0.00         1\n",
      "  b'0.0110'       0.00      0.00      0.00         0\n",
      "  b'0.0111'       0.00      0.00      0.00         1\n",
      "  b'0.0114'       0.00      0.00      0.00         1\n",
      "  b'0.0115'       0.00      0.00      0.00         0\n",
      "  b'0.0119'       0.00      0.00      0.00         1\n",
      "  b'0.0120'       0.20      0.50      0.29         2\n",
      "  b'0.0121'       0.00      0.00      0.00         0\n",
      "  b'0.0122'       0.00      0.00      0.00         2\n",
      "  b'0.0126'       0.00      0.00      0.00         1\n",
      "  b'0.0127'       0.00      0.00      0.00         1\n",
      "  b'0.0129'       0.00      0.00      0.00         0\n",
      "  b'0.0132'       0.00      0.00      0.00         2\n",
      "  b'0.0133'       0.00      0.00      0.00         0\n",
      "  b'0.0140'       0.00      0.00      0.00         1\n",
      "  b'0.0147'       0.00      0.00      0.00         1\n",
      "  b'0.0148'       0.00      0.00      0.00         1\n",
      "  b'0.0149'       0.00      0.00      0.00         1\n",
      "  b'0.0157'       0.00      0.00      0.00         0\n",
      "  b'0.0159'       0.00      0.00      0.00         0\n",
      "  b'0.0160'       0.00      0.00      0.00         2\n",
      "  b'0.0163'       0.00      0.00      0.00         1\n",
      "  b'0.0164'       0.00      0.00      0.00         1\n",
      "  b'0.0169'       0.00      0.00      0.00         0\n",
      "  b'0.0170'       0.00      0.00      0.00         1\n",
      "  b'0.0174'       0.00      0.00      0.00         0\n",
      "  b'0.0182'       0.00      0.00      0.00         0\n",
      "  b'0.0187'       0.00      0.00      0.00         1\n",
      "  b'0.0188'       0.00      0.00      0.00         1\n",
      "  b'0.0192'       0.00      0.00      0.00         0\n",
      "  b'0.0194'       0.00      0.00      0.00         0\n",
      "  b'0.0195'       0.00      0.00      0.00         2\n",
      "  b'0.0198'       0.00      0.00      0.00         1\n",
      "  b'0.0205'       0.00      0.00      0.00         1\n",
      "  b'0.0209'       0.00      0.00      0.00         0\n",
      "  b'0.0211'       0.00      0.00      0.00         0\n",
      "  b'0.0212'       0.00      0.00      0.00         0\n",
      "  b'0.0217'       0.00      0.00      0.00         3\n",
      "  b'0.0220'       0.00      0.00      0.00         0\n",
      "  b'0.0221'       0.00      0.00      0.00         1\n",
      "  b'0.0222'       0.00      0.00      0.00         1\n",
      "  b'0.0223'       0.00      0.00      0.00         3\n",
      "  b'0.0225'       0.00      0.00      0.00         1\n",
      "  b'0.0228'       0.00      0.00      0.00         2\n",
      "  b'0.0230'       0.00      0.00      0.00         0\n",
      "  b'0.0234'       0.00      0.00      0.00         1\n",
      "  b'0.0236'       0.00      0.00      0.00         1\n",
      "  b'0.0239'       0.00      0.00      0.00         1\n",
      "  b'0.0243'       0.00      0.00      0.00         1\n",
      "  b'0.0246'       0.00      0.00      0.00         0\n",
      "  b'0.0247'       0.00      0.00      0.00         1\n",
      "  b'0.0249'       0.00      0.00      0.00         0\n",
      "  b'0.0250'       0.00      0.00      0.00         1\n",
      "  b'0.0252'       0.00      0.00      0.00         3\n",
      "  b'0.0258'       0.00      0.00      0.00         1\n",
      "  b'0.0260'       0.00      0.00      0.00         1\n",
      "  b'0.0267'       0.00      0.00      0.00         2\n",
      "  b'0.0271'       0.00      0.00      0.00         0\n",
      "  b'0.0276'       0.00      0.00      0.00         2\n",
      "  b'0.0282'       0.00      0.00      0.00         1\n",
      "  b'0.0283'       0.00      0.00      0.00         0\n",
      "  b'0.0285'       0.00      0.00      0.00         0\n",
      "  b'0.0286'       0.00      0.00      0.00         0\n",
      "  b'0.0292'       0.00      0.00      0.00         1\n",
      "  b'0.0293'       0.00      0.00      0.00         1\n",
      "  b'0.0298'       0.00      0.00      0.00         1\n",
      "  b'0.0300'       0.00      0.00      0.00         1\n",
      "  b'0.0302'       0.00      0.00      0.00         1\n",
      "  b'0.0305'       0.00      0.00      0.00         0\n",
      "  b'0.0312'       0.00      0.00      0.00         2\n",
      "  b'0.0313'       0.00      0.00      0.00         0\n",
      "  b'0.0314'       0.00      0.00      0.00         1\n",
      "  b'0.0319'       0.00      0.00      0.00         0\n",
      "  b'0.0320'       0.00      0.00      0.00         0\n",
      "  b'0.0321'       0.00      0.00      0.00         1\n",
      "  b'0.0323'       0.00      0.00      0.00         0\n",
      "  b'0.0324'       0.00      0.00      0.00         1\n",
      "  b'0.0332'       0.00      0.00      0.00         0\n",
      "  b'0.0337'       0.00      0.00      0.00         0\n",
      "  b'0.0343'       0.00      0.00      0.00         0\n",
      "  b'0.0346'       0.00      0.00      0.00         1\n",
      "  b'0.0347'       0.00      0.00      0.00         0\n",
      "  b'0.0351'       0.00      0.00      0.00         2\n",
      "  b'0.0352'       0.00      0.00      0.00         1\n",
      "  b'0.0359'       0.00      0.00      0.00         0\n",
      "  b'0.0361'       0.00      0.00      0.00         1\n",
      "  b'0.0367'       0.00      0.00      0.00         0\n",
      "  b'0.0368'       0.00      0.00      0.00         2\n",
      "  b'0.0376'       0.00      0.00      0.00         1\n",
      "  b'0.0384'       0.00      0.00      0.00         0\n",
      "  b'0.0387'       0.00      0.00      0.00         1\n",
      "  b'0.0389'       0.00      0.00      0.00         0\n",
      "  b'0.0390'       0.00      0.00      0.00         1\n",
      "  b'0.0392'       0.00      0.00      0.00         1\n",
      "  b'0.0396'       0.00      0.00      0.00         1\n",
      "  b'0.0397'       0.00      0.00      0.00         1\n",
      "  b'0.0400'       0.00      0.00      0.00         1\n",
      "  b'0.0403'       0.00      0.00      0.00         1\n",
      "  b'0.0406'       0.00      0.00      0.00         1\n",
      "  b'0.0408'       0.00      0.00      0.00         0\n",
      "  b'0.0410'       0.00      0.00      0.00         0\n",
      "  b'0.0413'       0.00      0.00      0.00         0\n",
      "  b'0.0414'       0.00      0.00      0.00         1\n",
      "  b'0.0420'       0.00      0.00      0.00         1\n",
      "  b'0.0421'       0.00      0.00      0.00         1\n",
      "  b'0.0423'       0.00      0.00      0.00         0\n",
      "  b'0.0432'       0.00      0.00      0.00         1\n",
      "  b'0.0433'       0.00      0.00      0.00         1\n",
      "  b'0.0441'       0.00      0.00      0.00         1\n",
      "  b'0.0443'       0.00      0.00      0.00         1\n",
      "  b'0.0444'       0.00      0.00      0.00         1\n",
      "  b'0.0454'       0.00      0.00      0.00         0\n",
      "  b'0.0456'       0.00      0.00      0.00         1\n",
      "  b'0.0458'       0.00      0.00      0.00         0\n",
      "  b'0.0462'       0.00      0.00      0.00         1\n",
      "  b'0.0463'       0.00      0.00      0.00         0\n",
      "  b'0.0468'       0.00      0.00      0.00         1\n",
      "  b'0.0476'       0.00      0.00      0.00         2\n",
      "  b'0.0485'       0.00      0.00      0.00         0\n",
      "  b'0.0487'       0.00      0.00      0.00         0\n",
      "  b'0.0489'       0.00      0.00      0.00         0\n",
      "  b'0.0490'       0.00      0.00      0.00         1\n",
      "  b'0.0499'       0.00      0.00      0.00         1\n",
      "  b'0.0500'       0.00      0.00      0.00         0\n",
      "  b'0.0502'       0.00      0.00      0.00         0\n",
      "  b'0.0510'       0.00      0.00      0.00         0\n",
      "  b'0.0512'       0.00      0.00      0.00         1\n",
      "  b'0.0519'       0.00      0.00      0.00         0\n",
      "  b'0.0522'       0.00      0.00      0.00         0\n",
      "  b'0.0526'       0.00      0.00      0.00         1\n",
      "  b'0.0531'       0.00      0.00      0.00         1\n",
      "  b'0.0535'       0.00      0.00      0.00         1\n",
      "  b'0.0547'       0.00      0.00      0.00         0\n",
      "  b'0.0558'       0.00      0.00      0.00         1\n",
      "  b'0.0560'       0.00      0.00      0.00         2\n",
      "  b'0.0562'       0.00      0.00      0.00         1\n",
      "  b'0.0566'       0.00      0.00      0.00         1\n",
      "  b'0.0576'       0.00      0.00      0.00         1\n",
      "  b'0.0581'       0.00      0.00      0.00         0\n",
      "  b'0.0587'       0.00      0.00      0.00         0\n",
      "  b'0.0592'       0.00      0.00      0.00         1\n",
      "  b'0.0594'       0.00      0.00      0.00         0\n",
      "  b'0.0595'       0.00      0.00      0.00         0\n",
      "  b'0.0597'       0.00      0.00      0.00         0\n",
      "  b'0.0602'       0.00      0.00      0.00         0\n",
      "  b'0.0604'       0.00      0.00      0.00         0\n",
      "  b'0.0610'       0.00      0.00      0.00         1\n",
      "  b'0.0611'       0.00      0.00      0.00         1\n",
      "  b'0.0612'       0.00      0.00      0.00         0\n",
      "  b'0.0631'       0.00      0.00      0.00         1\n",
      "  b'0.0636'       0.00      0.00      0.00         0\n",
      "  b'0.0644'       0.00      0.00      0.00         0\n",
      "  b'0.0645'       0.00      0.00      0.00         1\n",
      "  b'0.0648'       0.00      0.00      0.00         1\n",
      "  b'0.0649'       0.00      0.00      0.00         0\n",
      "  b'0.0657'       0.00      0.00      0.00         1\n",
      "  b'0.0658'       0.00      0.00      0.00         1\n",
      "  b'0.0659'       0.00      0.00      0.00         0\n",
      "  b'0.0665'       0.00      0.00      0.00         0\n",
      "  b'0.0668'       0.00      0.00      0.00         1\n",
      "  b'0.0682'       0.00      0.00      0.00         1\n",
      "  b'0.0686'       0.00      0.00      0.00         1\n",
      "  b'0.0689'       0.00      0.00      0.00         1\n",
      "  b'0.0703'       0.00      0.00      0.00         0\n",
      "  b'0.0704'       0.00      0.00      0.00         0\n",
      "  b'0.0719'       0.00      0.00      0.00         0\n",
      "  b'0.0721'       0.00      0.00      0.00         0\n",
      "  b'0.0730'       0.00      0.00      0.00         1\n",
      "  b'0.0751'       0.00      0.00      0.00         1\n",
      "  b'0.0752'       0.00      0.00      0.00         0\n",
      "  b'0.0759'       0.00      0.00      0.00         0\n",
      "  b'0.0775'       0.00      0.00      0.00         0\n",
      "  b'0.0776'       0.00      0.00      0.00         0\n",
      "  b'0.0785'       0.00      0.00      0.00         0\n",
      "  b'0.0801'       0.00      0.00      0.00         0\n",
      "  b'0.0827'       0.00      0.00      0.00         0\n",
      "  b'0.0828'       0.00      0.00      0.00         1\n",
      "  b'0.0829'       0.00      0.00      0.00         0\n",
      "  b'0.0830'       0.00      0.00      0.00         0\n",
      "  b'0.0853'       0.00      0.00      0.00         0\n",
      "  b'0.0858'       0.00      0.00      0.00         0\n",
      "  b'0.0868'       0.00      0.00      0.00         0\n",
      "  b'0.0870'       0.00      0.00      0.00         0\n",
      "  b'0.0894'       0.00      0.00      0.00         0\n",
      "  b'0.0901'       0.00      0.00      0.00         0\n",
      "  b'0.0918'       0.00      0.00      0.00         1\n",
      "  b'0.0919'       0.00      0.00      0.00         1\n",
      "  b'0.0933'       0.00      0.00      0.00         0\n",
      "  b'0.0945'       0.00      0.00      0.00         1\n",
      "  b'0.0994'       0.00      0.00      0.00         1\n",
      "  b'0.1040'       0.00      0.00      0.00         1\n",
      "  b'0.1105'       0.00      0.00      0.00         0\n",
      "  b'0.1133'       0.00      0.00      0.00         0\n",
      "  b'0.1207'       0.00      0.00      0.00         0\n",
      "  b'0.1213'       0.00      0.00      0.00         0\n",
      "  b'0.1239'       0.00      0.00      0.00         0\n",
      "  b'0.1244'       0.00      0.00      0.00         0\n",
      "  b'0.1313'       0.00      0.00      0.00         1\n",
      "  b'0.1340'       0.00      0.00      0.00         0\n",
      "  b'0.1368'       0.00      0.00      0.00         1\n",
      "  b'0.1703'       0.00      0.00      0.00         0\n",
      "  b'0.1934'       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.00      0.01      0.00       339\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'-0.092', b'-0.046', b'0.0067', b'0.0610', b'-0.008', b'0.0108',\n",
       "       b'-0.065', b'0.0188', b'-0.099', b'0.0111'], dtype='|S6')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'0.0313', b'0.0468', b'0.0286', b'-0.002', b'0.0174', b'0.0220',\n",
       "       b'0.0209', b'-0.172', b'0.0025', b'0.0323'], dtype='|S9')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
